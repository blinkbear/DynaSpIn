python3 convert.py ~/.cache/huggingface/hub/models--meta-llama--Llama-2-13b-hf/snapshots/5c31dfb671ce7cfe2d7bb7c04375e44c55e815b1 --outfile ~/.cache/huggingface/hub/llama-2-13b/ggml-model-f16.gguf --outtype f16